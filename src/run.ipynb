{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter notebook list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-czech",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "multiple-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polar-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m WARNING: cannot import GeodescFeature2D from feature_geodesc, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import DelfFeature2D from feature_delf, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import ContextDescFeature2D from feature_contextdesc, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import LfNetFeature2D from feature_lfnet, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m\u001b[33m WARNING: cannot import KeyNetDescFeature2D from feature_keynet, check the file TROUBLESHOOTING.md\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "sys.path.append('../pyslam/')\n",
    "from config import Config\n",
    "from visual_odometry import VisualOdometry\n",
    "from camera  import PinholeCamera\n",
    "from ground_truth import groundtruth_factory\n",
    "from dataset import dataset_factory\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "from feature_tracker import feature_tracker_factory, FeatureTrackerTypes \n",
    "from feature_manager import feature_manager_factory\n",
    "from feature_types import FeatureDetectorTypes, FeatureDescriptorTypes, FeatureInfo\n",
    "from feature_matcher import feature_matcher_factory, FeatureMatcherTypes\n",
    "from tqdm import tqdm\n",
    "from feature_tracker_configs import FeatureTrackerConfigs\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Run VO')\n",
    "# parser.add_argument('--n', type=str, default='default', help='experimet name')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# exp_name = args.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = FeatureTrackerConfigs.test_configs\n",
    "folders = os.listdir('../data/dataset/sequences/')\n",
    "folders.sort()\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incoming-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = 'TXX_SIFT_ORB2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "formed-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4541 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:  TXX_SIFT_ORB2\n",
      "Folder:  00\n",
      "Processing KITTI Sequence of lenght:  4541\n",
      "using groundtruth:  kitti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4541 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/resize.cpp:4054: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f797f4561bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_R\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/VO_benchmark/pyslam/visual_odometry.py\u001b[0m in \u001b[0;36mtrack\u001b[0;34m(self, img, frame_id)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVoStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO_IMAGES_YET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessFirstFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVoStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGOT_FIRST_IMAGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/VO_benchmark/pyslam/visual_odometry.py\u001b[0m in \u001b[0;36mprocessFirstFrame\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprocessFirstFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# only detect on the current image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkps_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdes_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;31m# convert from list of keypoints to an array of points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkps_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkps_ref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/VO_benchmark/pyslam/feature_tracker.py\u001b[0m in \u001b[0;36mdetectAndCompute\u001b[0;34m(self, frame, mask)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# out: keypoints and descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/VO_benchmark/pyslam/feature_manager.py\u001b[0m in \u001b[0;36mdetectAndCompute\u001b[0;34m(self, frame, mask, filter)\u001b[0m\n\u001b[1;32m    958\u001b[0m                 \u001b[0mkps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[0;31m# 2. then, compute descriptors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                 \u001b[0mkps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_descriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkVerbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                     \u001b[0;31m#print('detector: ', self.detector_type.name, ', #features: ', len(kps))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-jr1ur_cf/opencv/modules/imgproc/src/resize.cpp:4054: error: (-215:Assertion failed) inv_scale_x > 0 in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "print('Experiment: ', exp_name)\n",
    "for f in folders:\n",
    "    print('Folder: ',f)\n",
    "    config = Config(f)\n",
    "\n",
    "    dataset = dataset_factory(config.dataset_settings)\n",
    "    groundtruth = groundtruth_factory(config.dataset_settings)\n",
    "\n",
    "    cam = PinholeCamera(config.cam_settings['Camera.width'], config.cam_settings['Camera.height'],\n",
    "                        config.cam_settings['Camera.fx'], config.cam_settings['Camera.fy'],\n",
    "                        config.cam_settings['Camera.cx'], config.cam_settings['Camera.cy'],\n",
    "                        config.DistCoef, config.cam_settings['Camera.fps'])\n",
    "\n",
    "    num_features=2000  # how many features do you want to detect and track?\n",
    "\n",
    "    # select your tracker configuration (see the file feature_tracker_configs.py) \n",
    "    # LK_SHI_TOMASI, LK_FAST\n",
    "    # SHI_TOMASI_ORB, FAST_ORB, ORB, BRISK, AKAZE, FAST_FREAK, SIFT, ROOT_SIFT, SURF, SUPERPOINT, FAST_TFEAT\n",
    "    tracker_config = model_config[exp_name]\n",
    "    tracker_config['num_features'] = num_features\n",
    "\n",
    "    feature_tracker = feature_tracker_factory(**tracker_config)\n",
    "    # create visual odometry object \n",
    "    vo = VisualOdometry(cam, groundtruth, feature_tracker)\n",
    "\n",
    "    # todo: add the trajectory visualization\n",
    "    traj_img_size = 800\n",
    "    traj_img = np.zeros((traj_img_size, traj_img_size, 3), dtype=np.uint8)\n",
    "    half_traj_img_size = int(0.5*traj_img_size)\n",
    "    draw_scale = 1\n",
    "\n",
    "    # second loop for iterating over all the frame\n",
    "    result = []  \n",
    "    for img_id in tqdm(range(dataset.max_frame_id)):\n",
    "        img = dataset.getImage(img_id)\n",
    "        if img is not None:\n",
    "            vo.track(img, img_id)\n",
    "            tmp = np.reshape(np.hstack((vo.cur_R, vo.cur_t)), 12)\n",
    "            result.append(' '.join([str(i) for i in tmp]))\n",
    "\n",
    "    # Save the results in the text files\n",
    "    res_base_path = os.path.join('../data/results/', exp_name)\n",
    "    res_folder_path = os.path.join(res_base_path, f+'.txt')\n",
    "    os.makedirs(res_base_path, exist_ok=True)\n",
    "\n",
    "    txt_file=open(res_folder_path, 'a') \n",
    "    txt_file.writelines(\"%s\\n\" % i for i in result) \n",
    "    txt_file.close() \n",
    "    print('Finished till:', exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-twins",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyslam",
   "language": "python",
   "name": "pyslam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
